{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XuyangAbert/PyGCL/blob/main/PyGCL_Prac_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQn0pXoZ7Nx6"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/XuyangAbert/PyGCL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8akcCQg1YdE"
      },
      "outputs": [],
      "source": [
        "# !pip install torch==2.1.2\n",
        "# !pip install torch-geometric==2.2.0\n",
        "!pip install torch\n",
        "!pip install torch-geometric\n",
        "!pip install numpy==1.24.3\n",
        "# !pip install numpy\n",
        "!pip install tqdm\n",
        "!pip install scipy\n",
        "!pip install networkx\n",
        "!pip install scikit-learn\n",
        "!pip install dgl==1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbJrYptunkYZ"
      },
      "outputs": [],
      "source": [
        "!pip install torch_scatter\n",
        "!pip install torch_sparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/PyGCL')"
      ],
      "metadata": {
        "id": "ZIvh7o92iA4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph Classification Tasks"
      ],
      "metadata": {
        "id": "_Mqd7JUuh4VS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WNxVjX3G72ab"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/PyGCL')\n",
        "import torch\n",
        "import os.path as osp\n",
        "import GCL.losses as L\n",
        "import GCL.augmentors as A\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from GCL.eval import get_split, SVMEvaluator\n",
        "from GCL.models import DualBranchContrast\n",
        "from torch_geometric.nn import GINConv, global_add_pool\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset,Planetoid\n",
        "\n",
        "\n",
        "def make_gin_conv(input_dim, out_dim):\n",
        "    return GINConv(nn.Sequential(nn.Linear(input_dim, out_dim), nn.ReLU(), nn.Linear(out_dim, out_dim)))\n",
        "\n",
        "\n",
        "class GConv(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
        "        super(GConv, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.batch_norms = nn.ModuleList()\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            if i == 0:\n",
        "                self.layers.append(make_gin_conv(input_dim, hidden_dim))\n",
        "            else:\n",
        "                self.layers.append(make_gin_conv(hidden_dim, hidden_dim))\n",
        "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "        project_dim = hidden_dim * num_layers\n",
        "        self.project = torch.nn.Sequential(\n",
        "            nn.Linear(project_dim, project_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(project_dim, project_dim))\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        z = x\n",
        "        zs = []\n",
        "        for conv, bn in zip(self.layers, self.batch_norms):\n",
        "            z = conv(z, edge_index)\n",
        "            z = F.relu(z)\n",
        "            z = bn(z)\n",
        "            zs.append(z)\n",
        "        gs = [global_add_pool(z, batch) for z in zs]\n",
        "        z, g = [torch.cat(x, dim=1) for x in [zs, gs]]\n",
        "        return z, g\n",
        "\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, encoder, augmentor):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.augmentor = augmentor\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        aug1, aug2 = self.augmentor\n",
        "        x1, edge_index1, edge_weight1 = aug1(x, edge_index)\n",
        "        x2, edge_index2, edge_weight2 = aug2(x, edge_index)\n",
        "        z, g = self.encoder(x, edge_index, batch)\n",
        "        z1, g1 = self.encoder(x1, edge_index1, batch)\n",
        "        z2, g2 = self.encoder(x2, edge_index2, batch)\n",
        "        return z, g, z1, z2, g1, g2\n",
        "\n",
        "\n",
        "def train(encoder_model, contrast_model, dataloader, optimizer):\n",
        "    encoder_model.train()\n",
        "    epoch_loss = 0\n",
        "    for data in dataloader:\n",
        "        data = data.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if data.x is None:\n",
        "            num_nodes = data.batch.size(0)\n",
        "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
        "\n",
        "        _, _, _, _, g1, g2 = encoder_model(data.x, data.edge_index, data.batch)\n",
        "        g1, g2 = [encoder_model.encoder.project(g) for g in [g1, g2]]\n",
        "        loss = contrast_model(g1=g1, g2=g2, batch=data.batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "def test(encoder_model, dataloader):\n",
        "    encoder_model.eval()\n",
        "    x = []\n",
        "    y = []\n",
        "    for data in dataloader:\n",
        "        data = data.to('cuda')\n",
        "        if data.x is None:\n",
        "            num_nodes = data.batch.size(0)\n",
        "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
        "        _, g, _, _, _, _ = encoder_model(data.x, data.edge_index, data.batch)\n",
        "        x.append(g)\n",
        "        y.append(data.y)\n",
        "    x = torch.cat(x, dim=0)\n",
        "    y = torch.cat(y, dim=0)\n",
        "\n",
        "    split = get_split(num_samples=x.size()[0], train_ratio=0.6, test_ratio=0.2)\n",
        "    result = SVMEvaluator(linear=True)(x, y, split)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcH3TJ4GpjYp"
      },
      "source": [
        "Example Codes for Graph Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L75VbQWa78h-"
      },
      "outputs": [],
      "source": [
        "def graph_classification():\n",
        "    device = torch.device('cuda')\n",
        "    path = osp.join(osp.expanduser('~'), 'datasets')\n",
        "    dataset = TUDataset(path, name='PTC_MR')\n",
        "    dataloader = DataLoader(dataset, batch_size=128)\n",
        "    input_dim = max(dataset.num_features, 1)\n",
        "\n",
        "    aug1 = A.Identity()\n",
        "    aug2 = A.RandomChoice([A.RWSampling(num_seeds=1000, walk_length=10),\n",
        "                           A.NodeDropping(pn=0.1),\n",
        "                           A.FeatureMasking(pf=0.1),\n",
        "                           A.EdgeRemoving(pe=0.1)], 1)\n",
        "    gconv = GConv(input_dim=input_dim, hidden_dim=32, num_layers=2).to(device)\n",
        "    encoder_model = Encoder(encoder=gconv, augmentor=(aug1, aug2)).to(device)\n",
        "    contrast_model = DualBranchContrast(loss=L.InfoNCE(tau=0.2), mode='G2G').to(device)\n",
        "\n",
        "    optimizer = Adam(encoder_model.parameters(), lr=0.00001)\n",
        "    test_results = []\n",
        "\n",
        "    with tqdm(total=100, desc='(T)') as pbar:\n",
        "        for epoch in range(1, 101):\n",
        "            loss = train(encoder_model, contrast_model, dataloader, optimizer)\n",
        "            if epoch % 5 == 0:\n",
        "                test_result = test(encoder_model, dataloader)\n",
        "                test_results.append([epoch,\n",
        "                                     test_result['micro_f1'],\n",
        "                                     test_result['macro_f1'],\n",
        "                                     loss])\n",
        "            # pbar.set_postfix({'loss': loss})\n",
        "            # pbar.update()\n",
        "    return test_results\n",
        "\n",
        "    # test_result = test(encoder_model, dataloader)\n",
        "    # print(f'(E): Best test F1Mi={test_result[\"micro_f1\"]:.4f}, F1Ma={test_result[\"macro_f1\"]:.4f}')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    test_results = graph_classification()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the codes from MVGL_node.py and GrapgCL.py to make it suitable for both the node-level and graph-level tasks."
      ],
      "metadata": {
        "id": "jqT63FfuikWh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P-lcGEP5AXRj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os.path as osp\n",
        "import GCL.losses as L\n",
        "import GCL.augmentors as A\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from GCL.eval import get_split, SVMEvaluator\n",
        "from GCL.models import DualBranchContrast\n",
        "from torch_geometric.nn import GINConv, global_add_pool\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset,Planetoid\n",
        "\n",
        "\n",
        "def make_gin_conv(input_dim, out_dim):\n",
        "    return GINConv(nn.Sequential(nn.Linear(input_dim, out_dim), nn.ReLU(), nn.Linear(out_dim, out_dim)))\n",
        "\n",
        "\n",
        "class GConv(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
        "        super(GConv, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.batch_norms = nn.ModuleList()\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            if i == 0:\n",
        "                self.layers.append(make_gin_conv(input_dim, hidden_dim))\n",
        "            else:\n",
        "                self.layers.append(make_gin_conv(hidden_dim, hidden_dim))\n",
        "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "        project_dim = hidden_dim * num_layers\n",
        "        self.project = torch.nn.Sequential(\n",
        "            nn.Linear(project_dim, project_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(project_dim, project_dim))\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        z = x\n",
        "        zs = []\n",
        "        for conv, bn in zip(self.layers, self.batch_norms):\n",
        "            z = conv(z, edge_index)\n",
        "            z = F.relu(z)\n",
        "            z = bn(z)\n",
        "            zs.append(z)\n",
        "        z = torch.cat(zs, dim=1)\n",
        "        z = self.project(z)\n",
        "        return z\n",
        "\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, encoder, augmentor):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.augmentor = augmentor\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        aug1, aug2 = self.augmentor\n",
        "        x1, edge_index1, edge_weight1 = aug1(x, edge_index)\n",
        "        x2, edge_index2, edge_weight2 = aug2(x, edge_index)\n",
        "        z = self.encoder(x, edge_index, batch)\n",
        "        z1 = self.encoder(x1, edge_index1, batch)\n",
        "        z2 = self.encoder(x2, edge_index2, batch)\n",
        "        return z, z1, z2\n",
        "\n",
        "def train_node(encoder_model, contrast_model, data, optimizer):\n",
        "  encoder_model.train()\n",
        "  optimizer.zero_grad()\n",
        "  z, z1, z2 = encoder_model(data.x, data.edge_index, data.batch)\n",
        "  loss = contrast_model(h1=z1, h2=z2, batch=data.batch)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss.item()\n",
        "\n",
        "def test_node(encoder_model, data):\n",
        "  encoder_model.eval()\n",
        "  z, _, _ = encoder_model(data.x, data.edge_index, data.batch)\n",
        "  split = get_split(num_samples=z.size()[0], train_ratio=0.6, test_ratio=0.2)\n",
        "  result = SVMEvaluator(linear=True)(z, data.y, split)\n",
        "  return result\n",
        "\n",
        "def node_classification(option):\n",
        "    device = torch.device('cuda')\n",
        "    path = osp.join(osp.expanduser('~'), 'datasets')\n",
        "    dataset = Planetoid(path, name='Cora', transform=T.NormalizeFeatures())\n",
        "    data = dataset[0].to(device)\n",
        "    input_dim = max(dataset.num_features, 1)\n",
        "\n",
        "    ## Choose for different sparsification methods for augmentation ##\n",
        "    # aug1 = A.Identity()\n",
        "    aug1 = A.PPRDiffusion(alpha = 0.2)\n",
        "    if option == 'fosr':\n",
        "      aug2 = A.FOSR(max_iterations = 20)\n",
        "    elif option == 'proxydelmin':\n",
        "      aug2 = A.PROXYDELMIN(max_iterations = 20, seed = 4438)\n",
        "    elif option == 'proxydelmax':\n",
        "      aug2 = A.PROXYDELMAX(max_iterations = 20, seed = 4438)\n",
        "    elif option == 'sdrf':\n",
        "      aug2 = A.SDRF(max_iterations = 20)\n",
        "    else:\n",
        "      aug2 = A.Identity()\n",
        "    gconv = GConv(input_dim=input_dim, hidden_dim=128, num_layers=2).to(device)\n",
        "    encoder_model = Encoder(encoder=gconv, augmentor=(aug1, aug2)).to(device)\n",
        "    contrast_model = DualBranchContrast(loss=L.InfoNCE(tau=0.2), mode='L2L').to(device)\n",
        "\n",
        "    optimizer = Adam(encoder_model.parameters(), lr=0.0001)\n",
        "    test_results = []\n",
        "\n",
        "    with tqdm(total=100, desc='(T)') as pbar:\n",
        "        for epoch in range(1, 101):\n",
        "            loss = train_node(encoder_model, contrast_model, data, optimizer)\n",
        "            if epoch % 5 == 0:\n",
        "                test_result = test_node(encoder_model, data)\n",
        "                test_results.append([epoch,\n",
        "                                     test_result['micro_f1'],\n",
        "                                     test_result['macro_f1'],\n",
        "                                     loss])\n",
        "            pbar.set_postfix({'loss': loss})\n",
        "            pbar.update()\n",
        "    return test_results\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res5 = node_classification('other')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC1hhlfDltuU",
        "outputId": "e5349dcc-22db-45a7-a758-1d0378fc7fb6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r(T):   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before sparsification:  torch.Size([2, 10556])\n",
            "Shape after sparsification:  torch.Size([2, 809194])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r(T):   0%|          | 0/100 [05:20<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMS6Iq2pCUCU"
      },
      "outputs": [],
      "source": [
        "res1 = node_classification('fosr')\n",
        "res2 = node_classification('proxydelmin')\n",
        "res3 = node_classification('proxydelmax')\n",
        "res4 = node_classification('sdrf')\n",
        "res5 = node_classification()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ueiSwHpAXZ",
        "outputId": "6f15c95e-3775-42f4-c0c8-cb0e048aedf1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 0.7182320441988951, 0.6868183972957068, 7.058711528778076],\n",
              " [10, 0.7090239410681399, 0.6887574527555437, 6.650815963745117],\n",
              " [15, 0.7255985267034991, 0.7033139699312111, 6.327315330505371],\n",
              " [20, 0.7845303867403315, 0.7617964628637377, 6.06370735168457],\n",
              " [25, 0.7753222836095764, 0.7788753362063533, 5.844958305358887],\n",
              " [30, 0.7863720073664825, 0.7719404999731175, 5.668851852416992],\n",
              " [35, 0.7900552486187845, 0.7806837406659869, 5.522538185119629],\n",
              " [40, 0.7753222836095764, 0.7545187088062921, 5.397488594055176],\n",
              " [45, 0.8103130755064457, 0.795856378688493, 5.288409233093262],\n",
              " [50, 0.8084714548802947, 0.7991368260196252, 5.195537567138672],\n",
              " [55, 0.8066298342541437, 0.7934009188143969, 5.107982635498047],\n",
              " [60, 0.7845303867403315, 0.7710376601492533, 5.031121730804443],\n",
              " [65, 0.8084714548802947, 0.790445760344556, 5.007458686828613],\n",
              " [70, 0.7808471454880295, 0.7644048329915439, 4.9321088790893555],\n",
              " [75, 0.8066298342541437, 0.8064882920759484, 4.86513614654541],\n",
              " [80, 0.7992633517495396, 0.7697042275128488, 4.803798675537109],\n",
              " [85, 0.7790055248618785, 0.7594706684852893, 4.749004364013672],\n",
              " [90, 0.7826887661141805, 0.7643940191322696, 4.696742057800293],\n",
              " [95, 0.7882136279926335, 0.7753529593933332, 4.64799690246582],\n",
              " [100, 0.7937384898710865, 0.7922869905953035, 4.601970672607422]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyM577l1jOjnn29uFuZB4yPJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}